{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "import norm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the in-text citations dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data structures\n",
    "#---\n",
    "valid_docs = dict()\n",
    "err_docs = dict()\n",
    "#--- Testing\n",
    "test_dates = defaultdict(list)\n",
    "test_titles = defaultdict(list)\n",
    "test_sources = defaultdict(list)\n",
    "test_ret_men = defaultdict(list)\n",
    "\n",
    "with open(\"../data/coci_intext_ref.csv\") as a_file:\n",
    "    csv_reader = csv.reader(a_file, delimiter=',')\n",
    "    \n",
    "    # skip the headers \n",
    "    #0)date\n",
    "    #1)doi\n",
    "    #2)full_text_source\n",
    "    #3)title\n",
    "    #4)abstract\n",
    "    #5)section\n",
    "    #6)intext_ref\n",
    "    #7)cito_fun\n",
    "    #8)sentiment\n",
    "    #9)ret_mention\n",
    "    #10)retracted\n",
    "    #11)note\n",
    "    #12)source_title\n",
    "    #13)source_id\n",
    "    #14)area\n",
    "    #15)category\n",
    "    \n",
    "    #skip the header\n",
    "    next(csv_reader, None)\n",
    "    \n",
    "    #iterate all the csv rows\n",
    "    for row in csv_reader:\n",
    "        \n",
    "        #Classify documents into Vlaid and Error \n",
    "        #---\n",
    "        cits_text = norm.norm_cits_text(row[6])\n",
    "        if len(cits_text) == 0:\n",
    "            err_docs[row[1]] = row[10]\n",
    "        else:\n",
    "            doi = row[1]\n",
    "            valid_docs[doi] = dict()\n",
    "            valid_docs[doi][\"year\"] = norm.norm_data(row[0])\n",
    "            valid_docs[doi][\"source\"] = norm.norm_source(row[2])\n",
    "            valid_docs[doi][\"title\"] = norm.norm_title(row[3])\n",
    "            valid_docs[doi][\"abstract\"] = norm.norm_abstract(row[4])\n",
    "            valid_docs[doi][\"cits_text\"] = cits_text\n",
    "            valid_docs[doi][\"section\"] = norm.norm_section(row[5], len(cits_text))\n",
    "            valid_docs[doi][\"cit_intent\"] = norm.norm_cit_intent(row[7])\n",
    "            valid_docs[doi][\"sentiment\"] = norm.norm_sentiment(row[8])\n",
    "            valid_docs[doi][\"retraction_mention\"] = norm.norm_retraction_men(row[9])\n",
    "            valid_docs[doi][\"retracted\"] = norm.norm_retraction_men(row[10])\n",
    "            valid_docs[doi][\"note\"] = norm.norm_note(row[11])\n",
    "            valid_docs[doi][\"source_title\"] = norm.norm_title(row[12])\n",
    "            valid_docs[doi][\"source_id\"] = norm.norm_source_id(row[13])\n",
    "            valid_docs[doi][\"area\"] = norm.norm_area(row[14])\n",
    "            valid_docs[doi][\"category\"] = norm.norm_category(row[15])\n",
    "            \n",
    "            #Testing the csv values\n",
    "            #---\n",
    "            test_dates[norm.norm_data(row[0])].append(doi)\n",
    "            test_sources[norm.norm_source(row[2])].append(doi)\n",
    "            test_titles[norm.norm_title(row[3])].append(doi)\n",
    "            test_ret_men[norm.norm_retraction_men(row[9])].append(doi)\n",
    "            is_valid = (len(valid_docs[doi][\"cits_text\"]) == len(valid_docs[doi][\"section\"]) == len(valid_docs[doi][\"cit_intent\"]) == len(valid_docs[doi][\"sentiment\"]))  \n",
    "            if not is_valid:\n",
    "                print(doi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns are the fields\n",
    "#Rows are the DOIs \n",
    "base_df = pd.DataFrame.from_dict(valid_docs).transpose()\n",
    "base_df[\"intext_cit\"] = list(zip(base_df[\"cits_text\"],base_df[\"cit_intent\"],base_df[\"sentiment\"],base_df[\"section\"]))\n",
    "\n",
    "periods = [\n",
    "    {\n",
    "        \"label\": \"1998-2004\",\n",
    "        \"years\": (1998,2004),\n",
    "        \"results\": {}\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"2005-2010\",\n",
    "        \"years\": (2005,2010),\n",
    "        \"results\": {}\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"2011-2017\",\n",
    "        \"years\": (2011,2017),\n",
    "        \"results\": {}\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate results and calculate basic stats\n",
    "## ---------------\n",
    "\n",
    "p_years = None\n",
    "def filter_fn(row):\n",
    "    if int(row[\"year\"]) in range(p_years[0],p_years[1]+1):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def intext_cits_map(df):\n",
    "    count_intext_cits = 0\n",
    "    groups = {\"sentiment\":defaultdict(int),\"cit_intent\":defaultdict(int),\"intext_cit\":defaultdict(int)}\n",
    "    for index, row in df.iterrows():\n",
    "        ## count total\n",
    "        count_intext_cits += len(row[\"section\"])\n",
    "        ## groups\n",
    "        for k in groups:\n",
    "            # if k = \"intext_cit\" then create a pattern including: sentiment, intent, mentions_retraction\n",
    "            if k == \"intext_cit\":\n",
    "                for index in range(0,len(row[k][0])):\n",
    "                    elem = (row[k][1][index],row[k][2][index],row[\"retraction_mention\"])\n",
    "                    groups[k][elem] += 1\n",
    "            else:\n",
    "                for elem in row[k]:\n",
    "                    groups[k][elem] += 1\n",
    "    \n",
    "    return {\"count\":count_intext_cits,\"groups\":groups}\n",
    "\n",
    "def sources_map(df):\n",
    "    groups = {\"subject\":defaultdict(int),\"intext_cits\": defaultdict(int)}\n",
    "    for index, row in df.iterrows():\n",
    "        ## groups\n",
    "        for k in groups:\n",
    "            \n",
    "            if k == \"subject\":\n",
    "                for a_index in range(0,len(row[\"area\"])):\n",
    "                    a = row[\"area\"][a_index]\n",
    "                    for c in row[\"category\"][a_index]:\n",
    "                        elem = (a,c)\n",
    "                        groups[k][elem] += 1\n",
    "            \n",
    "            if k == \"intext_cits\":\n",
    "                for a_index in range(0,len(row[\"area\"])):\n",
    "                    a = row[\"area\"][a_index]\n",
    "                    for index in range(0,len(row[\"intext_cit\"][0])):\n",
    "                        elem = (a, row[\"intext_cit\"][1][index], row[\"intext_cit\"][2][index], row[\"retraction_mention\"])\n",
    "                        groups[k][elem] += 1\n",
    "                        \n",
    "    return {\"groups\":groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in periods:\n",
    "    p_years = p[\"years\"]\n",
    "    p_df = base_df.copy()\n",
    "    m = p_df.apply(filter_fn, axis=1)\n",
    "    p_df = p_df[m]\n",
    "    \n",
    "    intext_cits = intext_cits_map(p_df)\n",
    "    sources = sources_map(p_df)\n",
    "    \n",
    "    p[\"results\"] = {\n",
    "        \n",
    "        ## Data frame\n",
    "        \"df\": p_df,\n",
    "        \n",
    "        \"citations\": p_df.groupby(['year']).size().reset_index(name='counts').to_records(index=False),\n",
    "        \n",
    "        ## documents\n",
    "        \"docs\": len(p_df),\n",
    "        \"paywall\": p_df[p_df[\"source\"] == \"other\"][\"source\"].count(),\n",
    "        \"open\": p_df[p_df[\"source\"] == \"doi\"][\"source\"].count(),\n",
    "        \n",
    "        ## in-text citations\n",
    "        \"total_intext_cits\": intext_cits[\"count\"],\n",
    "        \"avg_intext_cits\": round(intext_cits[\"count\"]/len(p_df),2),\n",
    "        \"mentions_retraction\": p_df[p_df[\"retraction_mention\"] == \"yes\"][\"retraction_mention\"].count(),\n",
    "        \"intext_cits_groups\": intext_cits[\"groups\"],\n",
    "        \n",
    "        ## sources\n",
    "        \"sources_groups\": sources[\"groups\"],        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print on file the results\n",
    "for p in periods:\n",
    "    csv_files = [\n",
    "        #p[label]+\"_gen.csv\", \n",
    "        p[\"label\"]+\"_citations.csv\", \n",
    "        p[\"label\"]+\"_intext_cits_gen.csv\", \n",
    "        p[\"label\"]+\"_sources_gen.csv\", \n",
    "        p[\"label\"]+\"_sources_intext_cits.csv\"]\n",
    "    \n",
    "    for f_name in csv_files:\n",
    "        \n",
    "        rows = []\n",
    "        \n",
    "        # A file \n",
    "        if f_name.endswith(\"_citations.csv\"):\n",
    "            rows.append([\"year\",\"count\"])\n",
    "            for val in p[\"results\"][\"citations\"]:\n",
    "                rows.append([val[0],val[1]])\n",
    "        \n",
    "        # A file \n",
    "        if f_name.endswith(\"_intext_cits_gen.csv\"):\n",
    "            rows.append([\"intent\",\"sentiment\",\"mentions_retraction\",\"count\"])\n",
    "            for k,val in p[\"results\"][\"intext_cits_groups\"][\"intext_cit\"].items():\n",
    "                rows.append([k[0],k[1],k[2],val])\n",
    "        \n",
    "        # A file \n",
    "        if f_name.endswith(\"_sources_gen.csv\"):\n",
    "            rows.append([\"area\",\"category\",\"count\"])\n",
    "            for k,val in p[\"results\"][\"sources_groups\"][\"subject\"].items():\n",
    "                rows.append([k[0],k[1],val])\n",
    "                \n",
    "        # A file \n",
    "        if f_name.endswith(\"_sources_intext_cits.csv\"):\n",
    "            rows.append([\"area\",\"intent\",\"sentiment\",\"mentions_retraction\",\"count\"])\n",
    "            for k,val in p[\"results\"][\"sources_groups\"][\"intext_cits\"].items():\n",
    "                rows.append([k[0],k[1],k[2],k[3],val])\n",
    "        \n",
    "        #Write on file\n",
    "        with open(\"../results/data/\"+f_name,\"w\") as outfile:\n",
    "            w = csv.writer(outfile)\n",
    "            for r in rows:\n",
    "                w.writerow(r)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
